{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "941741204a003f44",
   "metadata": {},
   "source": [
    "# Ejercicio 4: Modelo Probabilístico \n",
    "## Steven Erazo\n",
    "\n",
    "## Objetivo de la práctica \n",
    "- Comprender los componentes del modelo vectorial mediante cálculos manuales y observación directa.\n",
    "- Aplicar el modelo de espacio vectorial con TF-IDF para recuperar documentos relevantes.\n",
    "- Comparar la recuperación con BM25 frente a TF-IDF.\n",
    "- Analizar visualmente las diferencias entre los modelos.\n",
    "- Evaluar si los rankings generados son consistentes con lo que considerarías documentos relevantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93bafe7a6a4ef9e5",
   "metadata": {},
   "source": [
    "## Parte 0: Carga del Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad08bb8bd43ae327",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-21T14:16:07.323562Z",
     "start_time": "2025-05-21T14:16:05.364309Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "newsgroups = fetch_20newsgroups(subset='all', remove=('headers', 'footers', 'quotes'))\n",
    "newsgroupsdocs = newsgroups.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08591223",
   "metadata": {},
   "source": [
    "## Parte 0.2 : Limpieza de Corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b87c64d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documento 1:\n",
      "i am sure some bashers pens fans pretty confused about lack any kind posts about recent pens massacre devils actually i am bit puzzled too bit relieved however i am going put end nonpittsburghers relief bit praise pens man they killing those devils worse than i thought jagr just showed you he much better than his regular season stats he also lot fo fun watch playoffs bowman should let jagr lot fun next couple games since pens going beat pulp out jersey anyway i very disappointed not see islanders lose final regular season game pens rule\n",
      "\n",
      "Documento 2:\n",
      "my brother market highperformance video card supports vesa local bus mb ram does anyone suggestionsideas diamond stealth pro local bus orchid farenheit ati graphics ultra pro any other highperformance card please post or email thank you matt\n",
      "\n",
      "Documento 3:\n",
      "finally you said what you dream about mediterranean new area will greater after some years like your holocaust numbers ist july usa now here sweden its april still cold or you changed your calendar nothing mentioned true but let say its true shall azeri women children going pay price being raped killed tortured armenians you hearded something called geneva convention you facist ohhh i forgot how armenians fight nobody forgot you killings rapings torture against kurds turks once upon time ohhhh so swedish redcross workers do lie they too what ever you say regional killer if you dont like person then shoot him thats your policyl i i i confused i i search turkish planes you dont know what you talking about i turkeys government announced its giving weapons i azerbadjan since armenia started attack azerbadjan self not karabag province so search plane weapons since its content announced weapons if there one thats confused then thats you we right we do give weapons azeris since armenians started fight azerbadjan shoot down what armenian bread butter or arms personel russian army\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "# Stopwords mínimas personalizadas\n",
    "stopwords = {\n",
    "    'the', 'and', 'is', 'in', 'it', 'of', 'to', 'a', 'an', 'on', 'for', 'with',\n",
    "    'that', 'this', 'by', 'as', 'at', 'from', 'are', 'be', 'was', 'were', 'has', 'had', 'have'\n",
    "}\n",
    "\n",
    "# Regex para detectar palabras basura\n",
    "def es_basura(palabra):\n",
    "    # Demasiadas letras repetidas (como zzzz o aaa)\n",
    "    if re.fullmatch(r'(.)\\1{2,}', palabra):\n",
    "        return True\n",
    "    # Palabra sin vocales (y no es una sigla como \"USA\")\n",
    "    if not re.search(r'[aeiou]', palabra) and len(palabra) > 2:\n",
    "        return True\n",
    "    # Palabras muy largas y sin sentido\n",
    "    if len(palabra) > 20:\n",
    "        return True\n",
    "    # Contiene caracteres raros o mezcla de letras y números sin sentido\n",
    "    if re.search(r'[^a-z]', palabra):\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def limpiar_texto_robusto(texto):\n",
    "    texto = texto.lower()\n",
    "    texto = re.sub(r\"http\\S+|www\\S+|https\\S+\", '', texto)  # eliminar URLs\n",
    "    texto = re.sub(r'\\S+@\\S+', '', texto)  # eliminar correos\n",
    "    texto = texto.translate(str.maketrans('', '', string.punctuation))  # eliminar puntuación\n",
    "    texto = re.sub(r'\\d+', '', texto)  # eliminar números\n",
    "    palabras = texto.split()\n",
    "    palabras_filtradas = [\n",
    "        palabra for palabra in palabras\n",
    "        if palabra not in stopwords and not es_basura(palabra)\n",
    "    ]\n",
    "    return ' '.join(palabras_filtradas)\n",
    "\n",
    "# Aplicar limpieza al corpus\n",
    "corpus_limpio = [limpiar_texto_robusto(doc) for doc in newsgroups.data]\n",
    "\n",
    "# Ver ejemplos\n",
    "for i in range(3):\n",
    "    print(f\"Documento {i+1}:\\n{corpus_limpio[i]}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f8c7f78934f497",
   "metadata": {},
   "source": [
    "## Parte 1: Cálculo de TF, DF, IDF y TF-IDF\n",
    "\n",
    "### Actividad \n",
    "1. Utiliza el corpus cargado.\n",
    "2. Construye la matriz de términos (TF), y calcula la frecuencia de documentos (DF)\n",
    "3. Calcula TF-IDF utilizando sklearn.\n",
    "4. Visualiza los valores en un DataFrame para analizar las diferencias entre los términos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d2ebd9f1c1b6c787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Crear vectorizador de conteo\n",
    "vectorizer = CountVectorizer(stop_words='english')  # elimina stopwords para mejorar claridad\n",
    "X_counts = vectorizer.fit_transform(corpus_limpio)  # TF\n",
    "\n",
    "# Obtener nombres de las palabras (términos)\n",
    "terms = vectorizer.get_feature_names_out()\n",
    "\n",
    "# TF: matriz de términos (documento x término)\n",
    "tf_df = pd.DataFrame.sparse.from_spmatrix(X_counts, columns=terms)\n",
    "\n",
    "# DF: cuántos documentos contienen cada término\n",
    "df_counts = np.sum(X_counts > 0, axis=0).A1\n",
    "df_series = pd.Series(df_counts, index=terms).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5cac7d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Crear vectorizador TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(corpus_limpio)\n",
    "\n",
    "# Obtener nombres de las palabras (términos)\n",
    "tfidf_terms = tfidf_vectorizer.get_feature_names_out()\n",
    "\n",
    "# Matriz TF-IDF (mantener formato disperso para evitar MemoryError)\n",
    "tfidf_df = pd.DataFrame.sparse.from_spmatrix(X_tfidf, columns=tfidf_terms)\n",
    "#Saber el peso de tdidf_df de la matriz\n",
    "tfidf_weights = tfidf_df.sum(axis=0).sort_values(ascending=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "907f8b4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matriz TF-IDF (primeras filas):\n",
      "   aa  aaaaarrrrgh  aaaall  aaack  aaaggghhh  aaah  aaahh  aaahhhh  aaai  \\\n",
      "0   0            0       0      0          0     0      0        0     0   \n",
      "1   0            0       0      0          0     0      0        0     0   \n",
      "2   0            0       0      0          0     0      0        0     0   \n",
      "3   0            0       0      0          0     0      0        0     0   \n",
      "4   0            0       0      0          0     0      0        0     0   \n",
      "\n",
      "   aaaimit  ...  zxxslqqtnxpbtbsu  zy  zybnrreqyab  zyda  zygon  zymospoach  \\\n",
      "0        0  ...                 0   0            0     0      0           0   \n",
      "1        0  ...                 0   0            0     0      0           0   \n",
      "2        0  ...                 0   0            0     0      0           0   \n",
      "3        0  ...                 0   0            0     0      0           0   \n",
      "4        0  ...                 0   0            0     0      0           0   \n",
      "\n",
      "   zyxel  zyxelb  zz  zzip  \n",
      "0      0       0   0     0  \n",
      "1      0       0   0     0  \n",
      "2      0       0   0     0  \n",
      "3      0       0   0     0  \n",
      "4      0       0   0     0  \n",
      "\n",
      "[5 rows x 96848 columns]\n"
     ]
    }
   ],
   "source": [
    "# Mostrar las primeras filas de la matriz TF-IDF\n",
    "print(\"Matriz TF-IDF (primeras filas):\")\n",
    "print(tfidf_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64491bce5361e8b3",
   "metadata": {},
   "source": [
    "## Parte 2: Ranking de documentos usando TF-IDF\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Dada una consulta, construye el vector de consulta\n",
    "2. Calcula la similitud coseno entre la consulta y cada documento usando los vectores TF-IDF\n",
    "3. Genera un ranking de los documentos ordenados por relevancia.\n",
    "4. Muestra los resultados en una tabla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9d082c4a156b9554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "Número de documentos similares a la query 'chicken': 18846\n",
      "Documentos más similares a la query 'chicken':\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documento</th>\n",
       "      <th>Texto</th>\n",
       "      <th>Similitud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1315</td>\n",
       "      <td>\\nBut remember that had God extinguished the b...</td>\n",
       "      <td>0.292971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>13222</td>\n",
       "      <td>You are right in supposing that the problem is...</td>\n",
       "      <td>0.246714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15919</td>\n",
       "      <td>\\nWetteland comes off the DL on April 23rd, an...</td>\n",
       "      <td>0.236992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9048</td>\n",
       "      <td>I am 35 and am recovering from a case of Chick...</td>\n",
       "      <td>0.200208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>357</td>\n",
       "      <td>i read about the code you can put in to most a...</td>\n",
       "      <td>0.194932</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Documento                                              Texto  Similitud\n",
       "0       1315  \\nBut remember that had God extinguished the b...   0.292971\n",
       "1      13222  You are right in supposing that the problem is...   0.246714\n",
       "2      15919  \\nWetteland comes off the DL on April 23rd, an...   0.236992\n",
       "3       9048  I am 35 and am recovering from a case of Chick...   0.200208\n",
       "4        357  i read about the code you can put in to most a...   0.194932"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#similitud entre documentos\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# Calcular similitud coseno entre documentos escogiendo yo la query\n",
    "query = \"chicken\"\n",
    "query_tfidf = tfidf_vectorizer.transform([query])\n",
    "# Calcular similitud coseno entre la query y todos los documentos\n",
    "cosine_similarities = cosine_similarity(query_tfidf, X_tfidf)\n",
    "print(cosine_similarities)\n",
    "#mostrar cuantos elementos tiene cosine_similarities\n",
    "print(f\"Número de documentos similares a la query '{query}': {cosine_similarities.shape[1]}\")\n",
    "# Mostrar los documentos más similares a la query\n",
    "similar_docs_indices = cosine_similarities[0].argsort()[::-1][:5]  # Top 5 documentos\n",
    "print(f\"Documentos más similares a la query '{query}':\")\n",
    "#imprime con pandas en una tabla que tenga el indice del documento y el texto del documento y la similitud\n",
    "similar_docs = pd.DataFrame({\n",
    "    'Documento': similar_docs_indices,\n",
    "    'Texto': [newsgroupsdocs[i] for i in similar_docs_indices],\n",
    "    'Similitud': cosine_similarities[0][similar_docs_indices]\n",
    "})\n",
    "display(similar_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97061325508dc5f2",
   "metadata": {},
   "source": [
    "## Parte 3: Ranking con BM25\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Implementa un sistema de recuperación usando el modelo BM25.\n",
    "2. Usa la misma consulta del ejercicio anterior.\n",
    "3. Calcula el score BM25 para cada documento y genera un ranking.\n",
    "4. Compara manualmente con el ranking de TF-IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "85dd3c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documentos más relevantes para la consulta 'politics':\n",
      "Documento 1315: \n",
      "But remember that had God extinguished the blasphemous trash of Europe (and\n",
      "Imperialism with it), the United States would not exist today to put an end\n",
      "to those \"games\"....begs the question, which came first, the chicken or the\n",
      "egg??? (Puntuación: 10.853009075894631)\n",
      "Documento 15919: \n",
      "Wetteland comes off the DL on April 23rd, and will be evaluated on the 24th.\n",
      "He is throwing well, and without pain on the side.\n",
      "\n",
      "DeShields is not on the DL.  He suffered from the chicken pox and lost\n",
      "(this is the official total) 12 pounds.  He will be back, hopefully,\n",
      "next week.\n",
      "\n",
      "Walker will be back this tonight or tomorrow... (Puntuación: 10.09235926324862)\n",
      "Documento 13222: You are right in supposing that the problem is with the XmNcolormap\n",
      "(XtNcolormap for truly literate beings) not being set.  What you want\n",
      "to do is start your application with your new colormap.  This can be a\n",
      "chicken and egg sort of problem, however.  If you look at the Xt FAQ\n",
      "there is an example that should show how it can be done.  If not, let\n",
      "me know and maybe I can improve the example.\n",
      "\n",
      "--pete (Puntuación: 9.43134870176906)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Implementar un sistema de recuperacion usando el modelo BM25\n",
    "from rank_bm25 import BM25Okapi\n",
    "\n",
    "# Tokenizar el corpus limpio\n",
    "tokenized_corpus = [doc.split() for doc in corpus_limpio]\n",
    "# Crear el modelo BM25\n",
    "bm25 = BM25Okapi(tokenized_corpus)\n",
    "# Consultas de ejemplo\n",
    "queries = [\"chicken\"]\n",
    "# Calcular puntuaciones BM25 para cada consulta\n",
    "tokenized_query = queries\n",
    "scores = bm25.get_scores(tokenized_query)\n",
    "# Mostrar los documentos más relevantes para la consulta\n",
    "top_indices = scores.argsort()[::-1][:3]  # Top 5 documentos\n",
    "print(f\"Documentos más relevantes para la consulta '{query}':\")\n",
    "for idx in top_indices:\n",
    "\tprint(f\"Documento {idx}: {newsgroupsdocs[idx]} (Puntuación: {scores[idx]})\")\n",
    "print(\"\\n\")  # Nueva línea para separar consultas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c71b85e77b4b181",
   "metadata": {},
   "source": [
    "## Parte 4: Comparación visual entre TF-IDF y BM25\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Utiliza un gráfico de barras para visualizar los scores obtenidos por cada documento según TF-IDF y BM25.\n",
    "2. Compara los rankings visualmente.\n",
    "3. Identifica: ¿Qué documentos obtienen scores más altos en un modelo que en otro?\n",
    "4. Sugiere: ¿A qué se podría deber esta diferencia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16ad3d9d16c04d35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b97d171655ecfb",
   "metadata": {},
   "source": [
    "## Parte 5: Evaluación con consulta relevante\n",
    "\n",
    "### Actividad \n",
    "\n",
    "1. Elige una consulta y define qué documentos del corpus deberían considerarse relevantes.\n",
    "2. Evalúa Precision@3 o MAP para los rankings generados con TF-IDF y BM25.\n",
    "3. Responde: ¿Cuál modelo da mejores resultados respecto a tu criterio de relevancia?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5de59378900ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
